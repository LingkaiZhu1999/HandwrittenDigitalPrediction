{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "# use GPU for computations if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# temporarily patch this script until the MNIST data set download issue is resolved\n",
    "# https://github.com/pytorch/vision/issues/1938\n",
    "import urllib.request\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2ZfaQIUpDZvO"
   },
   "source": [
    "# Classification of hand-written digits\n",
    "\n",
    "We start by downloading and extracting the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuli\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# extract a complete PyTorch dataset\n",
    "def extract(dataset):\n",
    "    datasize = len(dataset)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=datasize, shuffle=False)\n",
    "    return next(iter(dataloader))\n",
    "\n",
    "# extract all test images and labels into PyTorch tensors\n",
    "# the training data will be loaded in batches during training\n",
    "test_X, test_Y = extract(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JetLsyAjDZv3"
   },
   "source": [
    "## The model\n",
    "\n",
    "The input data $X$ are grayscale images of $28\\times 28$ pixels. The first dimension will be the number of data points that are provided to the network. The input data is flattend into a matrix with $28 \\times 28 = 784$ columns using `X.view(-1, 784)`, where each colum represents one pixel. We then apply first the linear transformation $X W + b$ and then the softmax function to obtain the class probabilities predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # the weights of dimension (784, 10)\n",
    "        U1 = 4\n",
    "        U2 = 8\n",
    "        U3 = 12\n",
    "        pzero = 0.75\n",
    "        self.W1 = nn.Parameter(0.1 * torch.randn(U1, 1, 5, 5))\n",
    "        # the offset vector of dimension (10,)\n",
    "        self.b1 = nn.Parameter(torch.ones(U1)/U1)\n",
    "        self.W2 = nn.Parameter(0.1 * torch.randn(U2, U1, 5, 5))\n",
    "        self.b2 = nn.Parameter(torch.ones(U2)/U2)\n",
    "        self.W3 = nn.Parameter(0.1 * torch.randn(U3, U2, 4, 4))\n",
    "        self.b3 = nn.Parameter(torch.ones(U3)/U3)\n",
    "        self.W4 = nn.Parameter(0.1 * torch.randn(588, 200))\n",
    "        self.b4 = nn.Parameter(torch.ones(200)/200)\n",
    "        self.dropout =  nn.Dropout(p=pzero)\n",
    "        self.W5 = nn.Parameter(0.1 * torch.randn(200, 10))\n",
    "        self.b5 = nn.Parameter(torch.ones(10)/10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # flatten the data into a matrix with 28 x 28 = 784 columns\n",
    "        #X = X.view(-1, 784)\n",
    "        # compute the linear transformation\n",
    "        #Z1 = X.mm(self.W1) + self.b1\n",
    "        Q1 = F.relu(F.conv2d(X, self.W1, bias=self.b1, stride=1, padding=2))\n",
    "        #Q1 = torch.sigmoid(Z1)\n",
    "        #Z2 = Q1.mm(self.W2) + self.b2\n",
    "        Q2 = F.relu(F.conv2d(Q1, self.W2, bias=self.b2, stride=2, padding=2))\n",
    "        #Q2 = torch.sigmoid(Z2)\n",
    "        #Z3 = Q2.mm(self.W3) + self.b3\n",
    "        Q3 = F.relu(F.conv2d(Q2, self.W3, bias=self.b3, stride=2, padding=1))\n",
    "        #Q3 = torch.sigmoid(Z3)\n",
    "        #Z4 = Q3.mm(self.W4) + self.b4\n",
    "        #Z5 = Z4.mm(self.W5) + self.b5\n",
    "        U3flat = 7*7*12\n",
    "        Q3flat = Q3.view(-1, U3flat)\n",
    "        #Q4_linear = nn.Linear(U3flat, 200, device='cuda:0')\n",
    "        #Q4 = Q4_linear(Q3flat)\n",
    "        #Q5_linear = nn.Linear(200, 10, device='cuda:0')\n",
    "        #Q5 = Q5_linear(Q4)\n",
    "        Q4 = Q3flat.mm(self.W4) + self.b4\n",
    "        Q4dropout = self.dropout(Q4)\n",
    "        Q5 = Q4dropout.mm(self.W5) + self.b5\n",
    "        #Q = torch.sigmoid(Z4)\n",
    "        #print(self.b)\n",
    "        #print(np.shape(self.W))\n",
    "        # apply the softmax function\n",
    "        #G = F.softmax(Q.mm(self.W5) + self.b5, dim=1)\n",
    "        #Z = Q.mm(self.W5) + self.b5\n",
    "        return Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYMZmV_GDZwa"
   },
   "source": [
    "## The training\n",
    "\n",
    "We define the cross-entropy for the predicted probabilities $G$ (10-dimensional vectors) and the labels $Y$ (integers between 0 and 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOpD7LKcDZwe"
   },
   "outputs": [],
   "source": [
    "def crossentropy(G, Y):\n",
    "    # convert labels to onehot encoding\n",
    "    Y_onehot = torch.eye(10, device=device)[Y]\n",
    "\n",
    "    return -(Y_onehot * G.log()).sum(dim = 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSpeO0byDZwx"
   },
   "source": [
    "The next lines evaluate the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1B5xLOnDZw0"
   },
   "outputs": [],
   "source": [
    "def accuracy(G, Y):\n",
    "    return (G.argmax(dim=1) == Y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "rJ4jX9FDDZxB"
   },
   "source": [
    "We are ready to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: train accuracy   9.00% train cross-entropy  2.50  test accuracy  11.40% test cross-entropy   nan\n",
      "Step   100: train accuracy  89.00% train cross-entropy  0.36  test accuracy  86.75% test cross-entropy   nan\n",
      "Step   200: train accuracy  95.00% train cross-entropy  0.17  test accuracy  90.02% test cross-entropy   nan\n",
      "Step   300: train accuracy  88.00% train cross-entropy  0.35  test accuracy  91.14% test cross-entropy   nan\n",
      "Step   400: train accuracy  92.00% train cross-entropy  0.25  test accuracy  93.48% test cross-entropy   nan\n",
      "Step   500: train accuracy  97.00% train cross-entropy  0.15  test accuracy  94.62% test cross-entropy   nan\n",
      "Step   600: train accuracy  94.00% train cross-entropy  0.25  test accuracy  95.35% test cross-entropy   nan\n",
      "Step   700: train accuracy  95.00% train cross-entropy  0.13  test accuracy  95.59% test cross-entropy   nan\n",
      "Step   800: train accuracy  92.00% train cross-entropy  0.18  test accuracy  96.41% test cross-entropy   nan\n",
      "Step   900: train accuracy  96.00% train cross-entropy  0.15  test accuracy  96.50% test cross-entropy   nan\n",
      "Step  1000: train accuracy  96.00% train cross-entropy  0.13  test accuracy  96.27% test cross-entropy   nan\n",
      "Step  1100: train accuracy  96.00% train cross-entropy  0.11  test accuracy  96.92% test cross-entropy   nan\n",
      "Step  1200: train accuracy  98.00% train cross-entropy  0.05  test accuracy  97.06% test cross-entropy   nan\n",
      "Step  1300: train accuracy  98.00% train cross-entropy  0.07  test accuracy  96.89% test cross-entropy   nan\n",
      "Step  1400: train accuracy  96.00% train cross-entropy  0.13  test accuracy  97.32% test cross-entropy   nan\n",
      "Step  1500: train accuracy  97.00% train cross-entropy  0.06  test accuracy  97.22% test cross-entropy   nan\n",
      "Step  1600: train accuracy  99.00% train cross-entropy  0.05  test accuracy  97.32% test cross-entropy   nan\n",
      "Step  1700: train accuracy 100.00% train cross-entropy  0.03  test accuracy  97.34% test cross-entropy   nan\n",
      "Step  1800: train accuracy  98.00% train cross-entropy  0.05  test accuracy  97.48% test cross-entropy   nan\n",
      "Step  1900: train accuracy  97.00% train cross-entropy  0.08  test accuracy  97.30% test cross-entropy   nan\n",
      "Step  2000: train accuracy  97.00% train cross-entropy  0.07  test accuracy  97.82% test cross-entropy   nan\n",
      "Step  2100: train accuracy 100.00% train cross-entropy  0.02  test accuracy  97.56% test cross-entropy   nan\n",
      "Step  2200: train accuracy  96.00% train cross-entropy  0.13  test accuracy  97.47% test cross-entropy   nan\n",
      "Step  2300: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.92% test cross-entropy   nan\n",
      "Step  2400: train accuracy 100.00% train cross-entropy  0.05  test accuracy  97.70% test cross-entropy   nan\n",
      "Step  2500: train accuracy  97.00% train cross-entropy  0.07  test accuracy  98.07% test cross-entropy   nan\n",
      "Step  2600: train accuracy  98.00% train cross-entropy  0.04  test accuracy  97.72% test cross-entropy   nan\n",
      "Step  2700: train accuracy  98.00% train cross-entropy  0.05  test accuracy  97.89% test cross-entropy   nan\n",
      "Step  2800: train accuracy 100.00% train cross-entropy  0.02  test accuracy  97.90% test cross-entropy   nan\n",
      "Step  2900: train accuracy  98.00% train cross-entropy  0.07  test accuracy  97.75% test cross-entropy   nan\n",
      "Step  3000: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.93% test cross-entropy   nan\n",
      "Step  3100: train accuracy  98.00% train cross-entropy  0.07  test accuracy  97.91% test cross-entropy   nan\n",
      "Step  3200: train accuracy  98.00% train cross-entropy  0.03  test accuracy  97.93% test cross-entropy   nan\n",
      "Step  3300: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.13% test cross-entropy   nan\n",
      "Step  3400: train accuracy  98.00% train cross-entropy  0.03  test accuracy  98.02% test cross-entropy   nan\n",
      "Step  3500: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.03% test cross-entropy   nan\n",
      "Step  3600: train accuracy  98.00% train cross-entropy  0.06  test accuracy  98.09% test cross-entropy   nan\n",
      "Step  3700: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.21% test cross-entropy   nan\n",
      "Step  3800: train accuracy  98.00% train cross-entropy  0.07  test accuracy  98.12% test cross-entropy   nan\n",
      "Step  3900: train accuracy  99.00% train cross-entropy  0.05  test accuracy  98.30% test cross-entropy   nan\n",
      "Step  4000: train accuracy  99.00% train cross-entropy  0.06  test accuracy  98.12% test cross-entropy   nan\n",
      "Step  4100: train accuracy  99.00% train cross-entropy  0.01  test accuracy  98.22% test cross-entropy   nan\n",
      "Step  4200: train accuracy  97.00% train cross-entropy  0.08  test accuracy  98.15% test cross-entropy   nan\n",
      "Step  4300: train accuracy  97.00% train cross-entropy  0.05  test accuracy  98.36% test cross-entropy   nan\n",
      "Step  4400: train accuracy  97.00% train cross-entropy  0.11  test accuracy  98.14% test cross-entropy   nan\n",
      "Step  4500: train accuracy  98.00% train cross-entropy  0.09  test accuracy  98.25% test cross-entropy   nan\n",
      "Step  4600: train accuracy  96.00% train cross-entropy  0.07  test accuracy  98.34% test cross-entropy   nan\n",
      "Step  4700: train accuracy  98.00% train cross-entropy  0.05  test accuracy  98.28% test cross-entropy   nan\n",
      "Step  4800: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.06% test cross-entropy   nan\n",
      "Step  4900: train accuracy  98.00% train cross-entropy  0.05  test accuracy  98.30% test cross-entropy   nan\n",
      "Step  5000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.36% test cross-entropy   nan\n",
      "Step  5100: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.30% test cross-entropy   nan\n",
      "Step  5200: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.02% test cross-entropy   nan\n",
      "Step  5300: train accuracy  98.00% train cross-entropy  0.06  test accuracy  98.40% test cross-entropy   nan\n",
      "Step  5400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.08% test cross-entropy   nan\n",
      "Step  5500: train accuracy  98.00% train cross-entropy  0.05  test accuracy  98.18% test cross-entropy   nan\n",
      "Step  5600: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.30% test cross-entropy   nan\n",
      "Step  5700: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.21% test cross-entropy   nan\n",
      "Step  5800: train accuracy  98.00% train cross-entropy  0.03  test accuracy  98.47% test cross-entropy   nan\n",
      "Step  5900: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.27% test cross-entropy   nan\n",
      "Step  6000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.55% test cross-entropy   nan\n",
      "Step  6100: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.27% test cross-entropy   nan\n",
      "Step  6200: train accuracy  98.00% train cross-entropy  0.04  test accuracy  98.47% test cross-entropy   nan\n",
      "Step  6300: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.43% test cross-entropy   nan\n",
      "Step  6400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.25% test cross-entropy   nan\n",
      "Step  6500: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.42% test cross-entropy   nan\n",
      "Step  6600: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.19% test cross-entropy   nan\n",
      "Step  6700: train accuracy  98.00% train cross-entropy  0.03  test accuracy  98.45% test cross-entropy   nan\n",
      "Step  6800: train accuracy  97.00% train cross-entropy  0.08  test accuracy  98.31% test cross-entropy   nan\n",
      "Step  6900: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.29% test cross-entropy   nan\n",
      "Step  7000: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.33% test cross-entropy   nan\n",
      "Step  7100: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.27% test cross-entropy   nan\n",
      "Step  7200: train accuracy  99.00% train cross-entropy  0.01  test accuracy  98.39% test cross-entropy   nan\n",
      "Step  7300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.46% test cross-entropy   nan\n",
      "Step  7400: train accuracy  98.00% train cross-entropy  0.04  test accuracy  98.48% test cross-entropy   nan\n",
      "Step  7500: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.37% test cross-entropy   nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  7600: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.53% test cross-entropy   nan\n",
      "Step  7700: train accuracy  98.00% train cross-entropy  0.11  test accuracy  98.49% test cross-entropy   nan\n",
      "Step  7800: train accuracy  98.00% train cross-entropy  0.09  test accuracy  98.24% test cross-entropy   nan\n",
      "Step  7900: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.38% test cross-entropy   nan\n",
      "Step  8000: train accuracy  98.00% train cross-entropy  0.03  test accuracy  98.49% test cross-entropy   nan\n",
      "Step  8100: train accuracy  98.00% train cross-entropy  0.03  test accuracy  98.35% test cross-entropy   nan\n",
      "Step  8200: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.37% test cross-entropy   nan\n",
      "Step  8300: train accuracy  97.00% train cross-entropy  0.08  test accuracy  98.42% test cross-entropy   nan\n",
      "Step  8400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.50% test cross-entropy   nan\n",
      "Step  8500: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.45% test cross-entropy   nan\n",
      "Step  8600: train accuracy  98.00% train cross-entropy  0.10  test accuracy  98.45% test cross-entropy   nan\n",
      "Step  8700: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.30% test cross-entropy   nan\n",
      "Step  8800: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.21% test cross-entropy   nan\n",
      "Step  8900: train accuracy  99.00% train cross-entropy  0.01  test accuracy  98.47% test cross-entropy   nan\n",
      "Step  9000: train accuracy  98.00% train cross-entropy  0.05  test accuracy  98.46% test cross-entropy   nan\n",
      "Step  9100: train accuracy  98.00% train cross-entropy  0.04  test accuracy  98.51% test cross-entropy   nan\n",
      "Step  9200: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.42% test cross-entropy   nan\n",
      "Step  9300: train accuracy  97.00% train cross-entropy  0.04  test accuracy  98.16% test cross-entropy   nan\n",
      "Step  9400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.31% test cross-entropy   nan\n",
      "Step  9500: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.02% test cross-entropy   nan\n",
      "Step  9600: train accuracy  99.00% train cross-entropy  0.01  test accuracy  98.62% test cross-entropy   nan\n",
      "Step  9700: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.48% test cross-entropy   nan\n",
      "Step  9800: train accuracy  98.00% train cross-entropy  0.05  test accuracy  98.38% test cross-entropy   nan\n",
      "Step  9900: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.10% test cross-entropy   nan\n",
      "Step 10000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.46% test cross-entropy   nan\n",
      "Step 10100: train accuracy  99.00% train cross-entropy  0.05  test accuracy  98.54% test cross-entropy   nan\n",
      "Step 10200: train accuracy  98.00% train cross-entropy  0.09  test accuracy  98.36% test cross-entropy   nan\n",
      "Step 10300: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.47% test cross-entropy   nan\n",
      "Step 10400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.49% test cross-entropy   nan\n",
      "Step 10500: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.42% test cross-entropy   nan\n",
      "Step 10600: train accuracy  98.00% train cross-entropy  0.02  test accuracy  98.53% test cross-entropy   nan\n",
      "Step 10700: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.37% test cross-entropy   nan\n",
      "Step 10800: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.36% test cross-entropy   nan\n",
      "Step 10900: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.41% test cross-entropy   nan\n",
      "Step 11000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.37% test cross-entropy   nan\n",
      "Step 11100: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.56% test cross-entropy   nan\n",
      "Step 11200: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.61% test cross-entropy   nan\n",
      "Step 11300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.52% test cross-entropy   nan\n",
      "Step 11400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.42% test cross-entropy   nan\n",
      "Step 11500: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.49% test cross-entropy   nan\n",
      "Step 11600: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.33% test cross-entropy   nan\n",
      "Step 11700: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.45% test cross-entropy   nan\n",
      "Step 11800: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.34% test cross-entropy   nan\n",
      "Step 11900: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.53% test cross-entropy   nan\n",
      "Step 12000: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.43% test cross-entropy   nan\n",
      "Step 12100: train accuracy  97.00% train cross-entropy  0.07  test accuracy  98.42% test cross-entropy   nan\n",
      "Step 12200: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.58% test cross-entropy   nan\n",
      "Step 12300: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.53% test cross-entropy   nan\n",
      "Step 12400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.35% test cross-entropy   nan\n",
      "Step 12500: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.36% test cross-entropy   nan\n",
      "Step 12600: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.32% test cross-entropy   nan\n",
      "Step 12700: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.51% test cross-entropy   nan\n",
      "Step 12800: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.44% test cross-entropy   nan\n",
      "Step 12900: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.50% test cross-entropy   nan\n",
      "Step 13000: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.50% test cross-entropy   nan\n",
      "Step 13100: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.53% test cross-entropy   nan\n",
      "Step 13200: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.50% test cross-entropy   nan\n",
      "Step 13300: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.62% test cross-entropy   nan\n",
      "Step 13400: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.37% test cross-entropy   nan\n",
      "Step 13500: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.57% test cross-entropy   nan\n",
      "Step 13600: train accuracy  98.00% train cross-entropy  0.02  test accuracy  98.39% test cross-entropy   nan\n",
      "Step 13700: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.51% test cross-entropy   nan\n",
      "Step 13800: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.31% test cross-entropy   nan\n",
      "Step 13900: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.47% test cross-entropy   nan\n",
      "Step 14000: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.38% test cross-entropy   nan\n",
      "Step 14100: train accuracy 100.00% train cross-entropy  0.02  test accuracy  98.40% test cross-entropy   nan\n",
      "Step 14200: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.34% test cross-entropy   nan\n",
      "Step 14300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.36% test cross-entropy   nan\n",
      "Step 14400: train accuracy  99.00% train cross-entropy  0.02  test accuracy  98.38% test cross-entropy   nan\n",
      "Step 14500: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.51% test cross-entropy   nan\n",
      "Step 14600: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.44% test cross-entropy   nan\n",
      "Step 14700: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.56% test cross-entropy   nan\n",
      "Step 14800: train accuracy  99.00% train cross-entropy  0.08  test accuracy  98.37% test cross-entropy   nan\n",
      "Step 14900: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.38% test cross-entropy   nan\n",
      "Step 15000: train accuracy  99.00% train cross-entropy  0.03  test accuracy  98.51% test cross-entropy   nan\n"
     ]
    }
   ],
   "source": [
    "# initialize the test and training error statistics\n",
    "test_accuracy = []\n",
    "test_crossentropy = []\n",
    "test_iter = []\n",
    "train_accuracy = []\n",
    "train_crossentropy = []\n",
    "train_iter = []\n",
    "\n",
    "# initialize the neural network and move it to the GPU if needed\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# define the optimization algorithm\n",
    "learningrate = 0.005\n",
    "optimizer = optim.Adam(net.parameters(), lr=learningrate)\n",
    "gamma_min=0.0001\n",
    "gamma_max=0.003\n",
    "# define the data loader for batches of the training data\n",
    "batchsize = 100\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, num_workers=2, shuffle=True)\n",
    "\n",
    "# perform multiple training steps\n",
    "total_iterations = 12000 # total number of iterations\n",
    "t = 0 # current iteration\n",
    "done = False\n",
    "while not done:\n",
    "    gamma_new = gamma_min + (gamma_max-gamma_min)*np.exp(-t/2000)\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = gamma_new\n",
    "    for (batch_X, batch_Y) in trainloader:\n",
    "        # move batch to the GPU if needed\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #dropout\n",
    "        net.train()\n",
    "\n",
    "        # forward pass\n",
    "        batch_G = net(batch_X)\n",
    "        loss = F.cross_entropy(batch_G, batch_Y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # perform gradient descent step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # don't bother too much about the following lines!\n",
    "        with torch.no_grad():\n",
    "            # evaluate the performance on the training data at every 10th iteration\n",
    "            if t % 10 == 0:\n",
    "                train_crossentropy.append(loss.item())\n",
    "                train_accuracy.append(accuracy(batch_G, batch_Y).item())\n",
    "                train_iter.append(t)\n",
    "                \n",
    "            # evaluate the performance on the test data at every 100th iteration\n",
    "            if t % 100 == 0:\n",
    "                # move test data to the GPU if needed\n",
    "                X, Y = test_X.to(device), test_Y.to(device)\n",
    "                net.eval()\n",
    "\n",
    "                # compute predictions for the test data\n",
    "                G = net(X)\n",
    "                test_crossentropy.append(crossentropy(G, Y).item())\n",
    "                test_accuracy.append(accuracy(G, Y).item())\n",
    "                test_iter.append(t)\n",
    "\n",
    "                # print the iteration number and the accuracy of the predictions\n",
    "                print(f\"Step {t:5d}: train accuracy {100 * train_accuracy[-1]:6.2f}% \" \\\n",
    "                      f\"train cross-entropy {train_crossentropy[-1]:5.2f}  \" \\\n",
    "                      f\"test accuracy {100 * test_accuracy[-1]:6.2f}% \" \\\n",
    "                      f\"test cross-entropy {test_crossentropy[-1]:5.2f}\")\n",
    "            \n",
    "        # stop the training after the specified number of iterations\n",
    "        t += 1\n",
    "        if t > total_iterations:\n",
    "            done = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY9MEi2xDZxM"
   },
   "source": [
    "## The evaluation\n",
    "\n",
    "The remaining code produces the plots needed to evaluate the training and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "L_MSLJvoD28u",
    "outputId": "2be25bd3-0568-4590-faa2-39de35251d61"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Axis limits cannot be NaN or Inf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19216/1008110143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cross-entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_crossentropy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cross-entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mylim\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1736\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1737\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mset_ylim\u001b[1;34m(self, bottom, top, emit, auto, ymin, ymax)\u001b[0m\n\u001b[0;32m   4009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4010\u001b[0m         \u001b[0mbottom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_converted_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4011\u001b[1;33m         \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_converted_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbottom\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_validate_converted_limits\u001b[1;34m(self, limit, convert)\u001b[0m\n\u001b[0;32m   3599\u001b[0m             if (isinstance(converted_limit, Real)\n\u001b[0;32m   3600\u001b[0m                     and not np.isfinite(converted_limit)):\n\u001b[1;32m-> 3601\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Axis limits cannot be NaN or Inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3602\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_limit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Axis limits cannot be NaN or Inf"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cross-entropy\n",
    "plt.plot(train_iter, train_crossentropy, 'b-', label='Training data (mini-batch)')\n",
    "plt.plot(test_iter, test_crossentropy, 'r-', label='Test data')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross-entropy')\n",
    "plt.ylim([0, min(test_crossentropy) * 3])\n",
    "plt.title('Cross-entropy')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(train_iter, train_accuracy, 'b-', label='Training data (mini-batch)')\n",
    "plt.plot(test_iter, test_accuracy, 'r-', label='Test data')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.ylim([max(1 - (1 - test_accuracy[-1]) * 2, 0), 1])\n",
    "plt.title('Prediction accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "caWJ8PwaDZxO",
    "outputId": "1d3e738d-e278-425a-ddb7-bcda6a4565f4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate the network on 100 random test images\n",
    "with torch.no_grad():\n",
    "    # obtain 100 random samples from the test data set\n",
    "    random_X, random_Y = next(iter(torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True)))\n",
    "    \n",
    "    # move data to the GPU if needed\n",
    "    random_X, random_Y = random_X.to(device), random_Y.to(device)\n",
    "    \n",
    "    # compute the predictions for the sampled inputs\n",
    "    random_G = net(random_X)\n",
    "    random_Yhat = random_G.argmax(dim=1)\n",
    "    print(\"Accuracy: \",sum(random_Yhat == random_Y)/100)\n",
    "\n",
    "    # sort the predictions with the incorrect ones first\n",
    "    indices_incorrect_first = (random_Yhat == random_Y).float().argsort()\n",
    "\n",
    "# plot the images\n",
    "num_rows = 10\n",
    "num_cols = 10\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(num_cols, num_rows))\n",
    "\n",
    "for i, index in enumerate(indices_incorrect_first, 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # plot the image\n",
    "    plt.imshow(random_X[index, :, :].view(28, 28).cpu().numpy(), cmap=plt.cm.binary)\n",
    "    \n",
    "    # add the prediction as annotation (incorrect predictions in red, correct ones in blue)\n",
    "    color = 'blue' if random_Yhat[index] == random_Y[index] else 'red'\n",
    "    plt.text(0, 25, random_Yhat[index].item(), fontsize=25, color=color)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "colab": {
   "name": "mnist_one_layer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
